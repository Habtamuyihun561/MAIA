{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2WWw8U2K12LWpBIYVi3Am",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habtamuyihun561/MAIA/blob/main/ML_multi_class_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the Data"
      ],
      "metadata": {
        "id": "ohHFd71i3IJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t4fTNDq3AiC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "# Load the datasets\n",
        "#train_dataset = np.load('/content/drive/My Drive/train_dataset.npy')\n",
        "#test_dataset = np.load('/content/drive/My Drive/test_dataset.npy')\n",
        "train_dataset='/content/drive/My Drive/train_dataset_int.npy'\n",
        "test_dataset='/content/drive/My Drive/test_dataset_int.npy'\n",
        "\n",
        "train_dataset_onhot='/content/drive/My Drive/train_dataset_onehot.npy'\n",
        "test_dataset_onhot='/content/drive/My Drive/test_dataset_onehot.npy'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA ANALYSIS"
      ],
      "metadata": {
        "id": "Z-TvdAhc3QEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numpy arrays to pandas DataFrames\n",
        "train_df = pd.DataFrame(train_dataset)\n",
        "test_df = pd.DataFrame(test_dataset)\n",
        "\n",
        "train_df2 = pd.DataFrame(train_dataset_onhot)\n",
        "test_df2 = pd.DataFrame(test_dataset_onhot)\n",
        "\n",
        "# Display labels and number of features\n",
        "train_features = train_df.iloc[:, :-1]\n",
        "train_labels = train_df.iloc[:, -1]\n",
        "test_features = test_df.iloc[:, :-1]\n",
        "test_labels = test_df.iloc[:, -1]\n",
        "\n",
        "\n",
        "train_features2 = train_df2.iloc[:, :-1]\n",
        "train_labels2 = train_df2.iloc[:, -1]\n",
        "test_features2 = test_df2.iloc[:, :-1]\n",
        "test_labels2 = test_df2.iloc[:, -1]\n",
        "\n",
        "\n",
        "# Analyze the datasets\n",
        "print(\"Analysis of Training Dataset:\")\n",
        "print(f\"Number of samples: {train_features.shape[0]}\")\n",
        "print(f\"Number of features: {train_features.shape[1]}\")\n",
        "print(f\"Unique labels: {train_labels.unique()}\")\n",
        "print(\"Distribution of labels:\")\n",
        "print(train_labels.value_counts())\n",
        "\n",
        "print(\"\\nAnalysis of Testing Dataset:\")\n",
        "print(f\"Number of samples: {test_features.shape[0]}\")\n",
        "print(f\"Number of features: {test_features.shape[1]}\")\n",
        "print(f\"Unique labels: {test_labels.unique()}\")\n",
        "print(\"Distribution of labels:\")\n",
        "print(test_labels.value_counts())\n",
        "\n",
        "\n",
        "# Analyze the datasets\n",
        "print(\"Analysis of Training Dataset:\")\n",
        "print(f\"Number of samples: {train_features2.shape[0]}\")\n",
        "print(f\"Number of features: {train_features2.shape[1]}\")\n",
        "print(f\"Unique labels: {train_labels2.unique()}\")\n",
        "print(\"Distribution of labels:\")\n",
        "print(train_labels2.value_counts())\n",
        "\n",
        "print(\"\\nAnalysis of Testing Dataset:\")\n",
        "print(f\"Number of samples: {test_features2.shape[0]}\")\n",
        "print(f\"Number of features: {test_features2.shape[1]}\")\n",
        "print(f\"Unique labels: {test_labels2.unique()}\")\n",
        "print(\"Distribution of labels:\")\n",
        "print(test_labels2.value_counts())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tFTZ1pdf3PlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import classifiers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier, OutputCodeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n"
      ],
      "metadata": {
        "id": "M6EO2SlT3kQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2a. FEATURE REPRESENTATION"
      ],
      "metadata": {
        "id": "yNEqk7GM52aS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature representation by scatter plot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the dataset\n",
        "train_dataset = np.load('/content/drive/My Drive/train_dataset.npy')\n",
        "\n",
        "# Separate features and labels\n",
        "train_features = train_dataset[:, :-1]\n",
        "train_labels = train_dataset[:, -1]\n",
        "\n",
        "# Create a scatter plot pipeline\n",
        "scatter_plot_pipeline = Pipeline([\n",
        "    ('pca', PCA(n_components=2)),  # Reduce dimensionality to 2 for visualization\n",
        "])\n",
        "\n",
        "# Transform the features using PCA\n",
        "reduced_features = scatter_plot_pipeline.fit_transform(train_features)\n",
        "\n",
        "# Plot the scatter plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "for label in np.unique(train_labels):\n",
        "    indices = np.where(train_labels == label)\n",
        "    plt.scatter(reduced_features[indices, 0], reduced_features[indices, 1], label=label)\n",
        "plt.title('Feature Representation by Scatter Plot')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbsOrO5U52Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. DATA PREPARATION"
      ],
      "metadata": {
        "id": "FJSADg4g55Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XdXNShga54gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3a. DATASET NORMALIZATION"
      ],
      "metadata": {
        "id": "sIoiJLd56H6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create a dataset normalization pipeline\n",
        "normalization_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "# Apply normalization to the dataset\n",
        "normalized_features = normalization_pipeline.fit_transform(train_features)\n",
        "\n",
        "# Display the normalized features\n",
        "print(\"Normalized Features:\")\n",
        "print(normalized_features)\n"
      ],
      "metadata": {
        "id": "sNNcXJet6HPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3b. FEATURE SELECTION\n",
        "3b.1 ANOVA F-value"
      ],
      "metadata": {
        "id": "ToD0d-vY66He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Load the dataset\n",
        "train_dataset = np.load('/content/drive/My Drive/train_dataset.npy')\n",
        "\n",
        "# Separate features and labels\n",
        "train_features = train_dataset[:, :-1]\n",
        "train_labels = train_dataset[:, -1]\n",
        "\n",
        "# Create a pipeline for ANOVA F-value feature selection\n",
        "anova_pipeline = Pipeline([\n",
        "    ('anova', SelectKBest(score_func=f_classif)),  # ANOVA F-value feature selection\n",
        "])\n",
        "\n",
        "# Apply feature selection to the dataset\n",
        "selected_features_anova = anova_pipeline.fit_transform(train_features, train_labels)\n",
        "\n",
        "# Display the selected features\n",
        "print(\"Selected Features (ANOVA F-value):\")\n",
        "print(selected_features_anova)\n"
      ],
      "metadata": {
        "id": "sPviOtGo65Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b.2 Variance Threshold"
      ],
      "metadata": {
        "id": "Qhn5U8R_7GOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Create a pipeline for Variance Threshold feature selection\n",
        "variance_threshold_pipeline = Pipeline([\n",
        "    ('variance_threshold', VarianceThreshold()),  # Variance Threshold feature selection\n",
        "])\n",
        "\n",
        "# Apply feature selection to the dataset\n",
        "selected_features_variance_threshold = variance_threshold_pipeline.fit_transform(train_features)\n",
        "\n",
        "# Display the selected features\n",
        "print(\"Selected Features (Variance Threshold):\")\n",
        "print(selected_features_variance_threshold)\n"
      ],
      "metadata": {
        "id": "OzslJVq17Fd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b.3 Mutual Information"
      ],
      "metadata": {
        "id": "GKFGSbSa7H_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Create a pipeline for Mutual Information feature selection\n",
        "mutual_info_pipeline = Pipeline([\n",
        "    ('mutual_info', SelectKBest(score_func=mutual_info_classif)),  # Mutual Information feature selection\n",
        "])\n",
        "\n",
        "# Apply feature selection to the dataset\n",
        "selected_features_mutual_info = mutual_info_pipeline.fit_transform(train_features, train_labels)\n",
        "\n",
        "# Display the selected features\n",
        "print(\"Selected Features (Mutual Information):\")\n",
        "print(selected_features_mutual_info)\n"
      ],
      "metadata": {
        "id": "v0I5tH8c7Hnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "utWRoIl97LC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. MODEL"
      ],
      "metadata": {
        "id": "gWybwNh76NNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. CROSS VALIDATION"
      ],
      "metadata": {
        "id": "uXo7LuGZ7596"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a classification model."
      ],
      "metadata": {
        "id": "O3lz-63P6M8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 HOLD OUT METHOD"
      ],
      "metadata": {
        "id": "lSC1ji0V78KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "dataset = np.load('/content/drive/My Drive/train_dataset.npy')\n",
        "\n",
        "# Separate features and labels\n",
        "X = dataset[:, :-1]\n",
        "y = dataset[:, -1]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the classifier (RandomForestClassifier is used as an example)\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy (Hold-Out Method):\", accuracy)\n"
      ],
      "metadata": {
        "id": "ELqAfnXb7729"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 LEAVE ONE OUT CROSS VALIDATION"
      ],
      "metadata": {
        "id": "SxXCS9LU8BBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "# Perform LOOCV\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Initialize and train the classifier (RandomForestClassifier is used as an example)\n",
        "    classifier = RandomForestClassifier()\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing set\n",
        "    predictions = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate average accuracy\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(\"Average Accuracy (Leave-One-Out CV):\", average_accuracy)\n"
      ],
      "metadata": {
        "id": "ElZYxBxY8AAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 K FOLD CROSS VALIDATION"
      ],
      "metadata": {
        "id": "Q_VP5_UB8Enw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Initialize K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "# Perform K-Fold Cross-Validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Initialize and train the classifier (RandomForestClassifier is used as an example)\n",
        "    classifier = RandomForestClassifier()\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing set\n",
        "    predictions = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate average accuracy\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(\"Average Accuracy (K-Fold CV):\", average_accuracy)\n"
      ],
      "metadata": {
        "id": "7K_D22TL8EUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4 STRATIFIED FOLD CROSS VALIDATION\n",
        "#recommended"
      ],
      "metadata": {
        "id": "CyReYg748Mzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Initialize Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "# Perform Stratified K-Fold Cross-Validation\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Initialize and train the classifier (RandomForestClassifier is used as an example)\n",
        "    classifier = RandomForestClassifier()\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing set\n",
        "    predictions = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate average accuracy\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(\"Average Accuracy (Stratified K-Fold CV):\", average_accuracy)\n"
      ],
      "metadata": {
        "id": "bh6bpxyD8MfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. MODEL TRAINING"
      ],
      "metadata": {
        "id": "XAEtZIXT6Ong"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5a. CLASSIFIER WITH FULL FEATURES"
      ],
      "metadata": {
        "id": "f0WhBt5G7W5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "dataset = np.load('/content/drive/My Drive/train_dataset.npy')\n",
        "\n",
        "# Separate features and labels\n",
        "X = dataset[:, :-1]\n",
        "y = dataset[:, -1]\n",
        "\n",
        "# Initialize and train the classifier with full features (RandomForestClassifier is used as an example)\n",
        "classifier_full = RandomForestClassifier()\n",
        "classifier_full.fit(X, y)\n",
        "\n",
        "# Make predictions on the training set\n",
        "predictions_full = classifier_full.predict(X)\n",
        "\n",
        "# Evaluate the classifier with full features\n",
        "report_full = classification_report(y, predictions_full)\n",
        "print(\"Classifier with Full Features:\")\n",
        "print(report_full)\n"
      ],
      "metadata": {
        "id": "f_O0qpEY7WXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5b. CLASSIFIER WITH SELECTED FEATURES"
      ],
      "metadata": {
        "id": "P5-wS41j7YWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Trains the model on the training set.\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Initialize feature selection (ANOVA F-value is used as an example)\n",
        "feature_selection = SelectKBest(score_func=f_classif, k=10)  # Select top 10 features\n",
        "\n",
        "# Select features\n",
        "X_selected = feature_selection.fit_transform(X, y)\n",
        "\n",
        "# Initialize and train the classifier with selected features (RandomForestClassifier is used as an example)\n",
        "classifier_selected = RandomForestClassifier()\n",
        "classifier_selected.fit(X_selected, y)\n",
        "\n",
        "# Make predictions on the training set with selected features\n",
        "predictions_selected = classifier_selected.predict(X_selected)\n",
        "\n",
        "# Evaluate the classifier with selected features\n",
        "report_selected = classification_report(y, predictions_selected)\n",
        "print(\"Classifier with Selected Features:\")\n",
        "print(report_selected)\n"
      ],
      "metadata": {
        "id": "t3oe8GqM6OP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. MODEL EVALUATION"
      ],
      "metadata": {
        "id": "xSwczu2e6c8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluates the model's performance, using accuracy."
      ],
      "metadata": {
        "id": "P6tZ-Osi6Z19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy for the classifier with full features\n",
        "accuracy_full = accuracy_score(y, predictions_full)\n",
        "print(\"Accuracy (Classifier with Full Features):\", accuracy_full)\n"
      ],
      "metadata": {
        "id": "T9d-WjtjBXly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy for the classifier with selected features\n",
        "accuracy_selected = accuracy_score(y, predictions_selected)\n",
        "print(\"Accuracy (Classifier with Selected Features):\", accuracy_selected)\n"
      ],
      "metadata": {
        "id": "jQNOJfR36hPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The use of pipeline"
      ],
      "metadata": {
        "id": "g2aswBax9NGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a pipeline.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define a pipeline\n",
        "pipeline = Pipeline([\n",
        "    # Add steps to the pipeline as needed\n",
        "])\n"
      ],
      "metadata": {
        "id": "gOceApxQ9MvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5a. PIPELINE WITH FEATURE SELECTION"
      ],
      "metadata": {
        "id": "ds1PZQhU9Uko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define a pipeline with feature selection\n",
        "pipeline_feature_selection = Pipeline([\n",
        "    ('feature_selection', SelectKBest(score_func=f_classif)),\n",
        "    ('classification', RandomForestClassifier())  # Example classifier\n",
        "])\n"
      ],
      "metadata": {
        "id": "Lx3mjPDH9UJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5b. PIPELINE WITH PARAMETER OPTIMIZATION"
      ],
      "metadata": {
        "id": "u0BFP8xH9fTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define a pipeline with feature selection\n",
        "pipeline_feature_selection = Pipeline([\n",
        "    ('feature_selection', SelectKBest(score_func=f_classif)),\n",
        "    ('classification', RandomForestClassifier())  # Example classifier\n",
        "])\n"
      ],
      "metadata": {
        "id": "9fc5uJpq9fDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5c. PIPELINE WITH CROSS VALIDATION"
      ],
      "metadata": {
        "id": "BC3C2Spt9kkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define a pipeline with cross-validation\n",
        "pipeline_cross_validation = Pipeline([\n",
        "    ('classification', RandomForestClassifier())  # Example classifier\n",
        "])\n"
      ],
      "metadata": {
        "id": "A2jKmKJn9kUt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}