{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habtamuyihun561/MAIA/blob/main/AIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GlshPm6RjIv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580953e8-5187-4d83-9e42-8d7fab1ff456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UNN5Sh8tkh3j"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import exposure, io\n",
        "from skimage import exposure\n",
        "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT76G6rZRR0i"
      },
      "source": [
        "In Python, the notation List[np.ndarray] -> np.ndarray is a type hint often used in function signatures to specify the types of arguments and the return type of a function. Let's break down the meaning:\n",
        "\n",
        "List[np.ndarray]: This specifies that the function expects an argument which is a list, where each element of the list is an instance of np.ndarray. np.ndarray is a type provided by the NumPy library, commonly used for handling arrays (n-dimensional arrays). Therefore, List[np.ndarray] indicates a list of these arrays.\n",
        "\n",
        "-> np.ndarray: This part of the notation indicates the return type of the function. It tells you that the function is expected to return an np.ndarray object.\n",
        "\n",
        "Combining these, the entire type hint List[np.ndarray] -> np.ndarray is commonly found in the definition of a function that takes a list of np.ndarray objects as input and returns a single np.ndarray object. Hereâ€™s a simple example to illustrate this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV9dADBLRJoo",
        "outputId": "76596011-d7e2-4c16-92fd-7741b75a1f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3 4 5 6]\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "# tip codes:\n",
        "import numpy as np\n",
        "\n",
        "def combine_arrays(arrays: List[np.ndarray]) -> np.ndarray:\n",
        "    \"\"\"Combine a list of numpy arrays into a single array.\"\"\"\n",
        "    return np.concatenate(arrays)\n",
        "\n",
        "# Example usage\n",
        "array1 = np.array([1, 2, 3])\n",
        "array2 = np.array([4, 5, 6])\n",
        "result = combine_arrays([array1, array2])\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0aaEeZAj0Xh"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade numpy opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xfVMEw_bk1Gs"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_images_for_reference(image_dir, image_format=\".JPG\"):\n",
        "    \"\"\"Load images to determine the reference image based on median brightness.\"\"\"\n",
        "    brightness = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith(image_format):\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is not None:\n",
        "                # Calculate and store brightness along with the image path\n",
        "                current_brightness = np.mean(image)\n",
        "                brightness.append((current_brightness, img_path))\n",
        "\n",
        "    # Determine the reference image by median brightness\n",
        "    median_brightness = np.median([b[0] for b in brightness])\n",
        "    reference_image_path = min(brightness, key=lambda x: abs(x[0] - median_brightness))[1]\n",
        "    return cv2.imread(reference_image_path, cv2.IMREAD_GRAYSCALE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxCcqoslSIE8"
      },
      "source": [
        "**Tip**\n",
        "closest_img = min(images, key=lambda x: float(abs(np.mean(x) - median_brightness)))\n",
        "\n",
        "images: This is an iterable (probably a list) containing items that are likely numpy arrays representing images. Each x in images is one of these arrays.\n",
        "\n",
        "min() Function: The min() function is used to find the element in the iterable images that has the smallest value of the key specified. The key is a function that determines how the \"smallness\" is calculated for each element.\n",
        "\n",
        "Lambda Function lambda x: float(abs(np.mean(x) - median_brightness)):\n",
        "\n",
        "lambda x: This is a lambda function that takes an argument x, where x is an individual element from images.\n",
        "np.mean(x): This computes the mean (average) brightness of the image x. Assuming x is a NumPy array, np.mean(x) will calculate the average value of all pixels if x is a grayscale image, or the average across all pixels and color channels if x is a color image.\n",
        "median_brightness: This is a variable (not defined in the snippet) which likely holds the median brightness of some collection of images or a target brightness value that you want to match.\n",
        "abs(np.mean(x) - median_brightness): This calculates the absolute difference between the mean brightness of the image x and median_brightness. It measures how far the average brightness of the image x is from the median_brightness.\n",
        "float(...): This ensures that the result is a floating-point number. This is somewhat redundant here because the result of abs with NumPy operations would already be a float, but it ensures type consistency.\n",
        "Finding the Closest Image: The min() function uses the lambda function as a key to find the image x in images whose mean brightness is closest to the median brightness (i.e., the image for which the absolute difference between its mean brightness and the median brightness is the smallest).\n",
        "\n",
        "closest_img: This variable will store the image from images that has the mean brightness closest to median_brightness.\n",
        "\n",
        "The code is effectively selecting the image from a set that is most similar in brightness to a specified median brightness, which is useful in applications where consistency in brightness among images is desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "coe_f6V2kXZj"
      },
      "outputs": [],
      "source": [
        "def batch_process_images(image_dir, reference_image, histogram_match_dir,denoised_dir, batch_size=10):\n",
        "    \"\"\"Process images in batches using the determined reference image and save them.\"\"\"\n",
        "    filenames = [f for f in os.listdir(image_dir) if f.endswith('.JPG')]\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_files = filenames[i:i+batch_size]\n",
        "        batch_images = []\n",
        "        for f in batch_files:\n",
        "            img_path = os.path.join(image_dir, f)\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is not None:\n",
        "                image = image.astype(np.uint8)  # Convert image to uint8\n",
        "                batch_images.append(image)\n",
        "        matched_images = [histogram_matching(img, reference_image) for img in batch_images]\n",
        "        processed_images = [apply_non_local_means(unsharp_mask(apply_clahe(img))) for img in matched_images]\n",
        "\n",
        "        save_images(matched_images, batch_files, histogram_match_dir)\n",
        "        save_images(processed_images, batch_files, denoised_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U2yeyLWgkmzp"
      },
      "outputs": [],
      "source": [
        "def histogram_matching(source_image, reference_image):\n",
        "    \"\"\"Apply histogram matching from skimage.\"\"\"\n",
        "    return exposure.match_histograms(source_image, reference_image, channel_axis=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sT6HZea7k2mK"
      },
      "outputs": [],
      "source": [
        "def apply_clahe(image):\n",
        "    \"\"\"Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to an image.\"\"\"\n",
        "    if image.dtype != np.uint8:\n",
        "        image = np.uint8(image)  # Ensure image is in uint8 format\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return clahe.apply(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_cjMPty3qACo"
      },
      "outputs": [],
      "source": [
        "def unsharp_mask(image, sigma=0.25, strength=0.5):\n",
        "    \"\"\"Applies unsharp mask to enhance image sharpness.\"\"\"\n",
        "    blurred = cv2.GaussianBlur(image, (0, 0), sigma)\n",
        "    sharpened = cv2.addWeighted(image, 1.0 + strength, blurred, -strength, 0)\n",
        "    return sharpened"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iQxvbIqAk9dS"
      },
      "outputs": [],
      "source": [
        "def apply_non_local_means(image):\n",
        "    \"\"\"Apply non-local means denoising.\"\"\"\n",
        "    return cv2.fastNlMeansDenoising(image, None, 12, 9, 23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "stJk9bofk-Rf"
      },
      "outputs": [],
      "source": [
        "def save_images(images, filenames, output_dir):\n",
        "    \"\"\"Save processed images to the specified directory using their original filenames.\"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    for img, filename in zip(images, filenames):\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        cv2.imwrite(output_path, img.astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A3DUdOa1lDMH"
      },
      "outputs": [],
      "source": [
        "radiograph_img_dir= \"/content/drive/My Drive/AIA/Radiographs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfPz1Kv_k4BX"
      },
      "outputs": [],
      "source": [
        "\n",
        "reference_image = load_images_for_reference(radiograph_img_dir)\n",
        "\n",
        "matched_img=\"/content/drive/My Drive/AIA/Histogram_Matched\"\n",
        "\n",
        "denoised_img=\"/content/drive/My Drive/AIA/Denoised_CLAHE\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PBHCShWrAaX"
      },
      "outputs": [],
      "source": [
        "batch_process_images(radiograph_img_dir, reference_image,matched_img ,denoised_img, batch_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpCis89aS-WK"
      },
      "source": [
        "This line of code uses the match_histograms function, which is likely from the skimage.exposure module (part of the scikit-image library in Python). The function is used to transform the histogram of an input image (source_image) so that its histogram matches that of a reference image (reference_image).\n",
        "\n",
        "The parameter channel_axis specifies the axis of the array that corresponds to the color channels in the images:\n",
        "\n",
        "channel_axis=None: This implies that the images are treated as grayscale images, where there is no specific axis for color channels. Therefore, the entire image is processed as a single channel.\n",
        "\n",
        "If channel_axis is specified (e.g., channel_axis=-1 or channel_axis=2): This tells the function that the images are in a format where one of the axes corresponds to different color channels (commonly, RGB images). Specifying this parameter allows the function to apply histogram matching separately for each channel of the images. For example, in a typical color image with shape (height, width, channels), the channel_axis would be -1 or 2, indicating that the channels (like RGB) are on the last axis.\n",
        "\n",
        "In summary, the channel_axis parameter helps the match_histograms function understand whether it is dealing with grayscale images or color images with specific channels, and how to appropriately apply histogram matching to them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x52Hgg7Pbxnl"
      },
      "source": [
        "#Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Vg_kIaIsEySs"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder, batch_size=50):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            filenames.append(filename)\n",
        "            if len(images) == batch_size:\n",
        "                yield images, filenames  # Use yield to generate a batch\n",
        "                images = []  # Reset for next batch\n",
        "                filenames = []\n",
        "    if images:  # Check if there are leftover images after the last full batch\n",
        "        yield images, filenames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAWAnUXsQ76a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Default title text\n",
        "\n",
        "# Example Usage\n",
        "folder_path = 'path/to/your/images'\n",
        "for batch_images, batch_filenames in load_images_from_folder(folder_path, batch_size=50):\n",
        "    print(f\"Processed a batch of {len(batch_images)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(images, filenames, folder):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    for img, filename in zip(images, filenames):\n",
        "        cv2.imwrite(os.path.join(folder, filename), img)"
      ],
      "metadata": {
        "id": "WJ0jV7hB4hi8"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "bulUreriE8fr"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def adaptive_mean_thresholding(images):\n",
        "    thresholded_images = []\n",
        "    for image in images:\n",
        "        thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                       cv2.THRESH_BINARY, 115, -8)#87, -3, 97\n",
        "        thresholded_images.append(thresh)\n",
        "    return thresholded_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "hbuRWP_1E_Dg"
      },
      "outputs": [],
      "source": [
        "def adaptive_gaussian_thresholding(images):\n",
        "    thresholded_images = []\n",
        "    for image in images:\n",
        "        thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                       cv2.THRESH_BINARY, 125,-8)#67, 3\n",
        "        thresholded_images.append(thresh)\n",
        "    return thresholded_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Y-ICw8LtFBBT"
      },
      "outputs": [],
      "source": [
        "def adaptive_niblack_thresholding(images):\n",
        "    from skimage.filters import threshold_niblack\n",
        "    thresholded_images = []\n",
        "    for image in images:\n",
        "        thresh = threshold_niblack(image,window_size=115, k=-0.4 )#window_size=155, k=0.1\n",
        "        binary_image = image > thresh\n",
        "        thresholded_images.append((binary_image * 255).astype(np.uint8))\n",
        "    return thresholded_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ircH8XtaFDDg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def otsu_thresholding(images):\n",
        "    thresholded_images = []\n",
        "    for image in images:\n",
        "        _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        thresholded_images.append(thresh)\n",
        "    return thresholded_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "rTYZgfg9FGxz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_images(source_folder, save_folder_base, thresholding_function):\n",
        "    for images, filenames in load_images_from_folder(source_folder):\n",
        "        # Apply thresholding function\n",
        "        thresholded_images = thresholding_function(images)\n",
        "        # Save the results\n",
        "        save_folder = os.path.join(save_folder_base, thresholding_function.__name__)\n",
        "        save_images(thresholded_images, filenames, save_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "source_folder = \"/content/drive/My Drive/AIA/Denoised_CLAHE\"\n",
        "save_folder_base = \"/content/drive/My Drive/AIA\"\n"
      ],
      "metadata": {
        "id": "1Pl1WpnS4rH_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_images(source_folder, save_folder_base, adaptive_mean_thresholding)"
      ],
      "metadata": {
        "id": "bh5kr7EI4y8u"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_images(source_folder, save_folder_base, adaptive_gaussian_thresholding)"
      ],
      "metadata": {
        "id": "3guDhICx41Um"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_images(source_folder, save_folder_base, adaptive_niblack_thresholding)"
      ],
      "metadata": {
        "id": "XZzhsci743CI"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZO5MtlyEpxn"
      },
      "outputs": [],
      "source": [
        "process_images(source_folder, save_folder_base, otsu_thresholding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxEwNFjdErGk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga0ajNKBdF6C"
      },
      "source": [
        "#Apply Masking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder, batch_size=50):\n",
        "    \"\"\" Generator to yield batches of images and their filenames. \"\"\"\n",
        "    images = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if image is not None:\n",
        "            images.append(image)\n",
        "            filenames.append(filename)\n",
        "            if len(images) == batch_size:\n",
        "                yield images, filenames\n",
        "                images, filenames = [], []\n",
        "    if images:\n",
        "        yield images, filenames"
      ],
      "metadata": {
        "id": "OWQjP9nI-zhu"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(images, filenames, folder):\n",
        "    \"\"\" Save processed images to a specified folder. \"\"\"\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    for img, filename in zip(images, filenames):\n",
        "        cv2.imwrite(os.path.join(folder, filename), img)"
      ],
      "metadata": {
        "id": "PWiSHooM__5Z"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_elliptical_mask(image):\n",
        "    \"\"\" Create an elliptical mask for given image dimensions. \"\"\"\n",
        "    height, width = image.shape\n",
        "    center = (width // 2, round(height * 0.6))  # Center of the ellipse\n",
        "    axes = (width // 3, height // 3)  # Semi-major and semi-minor axes\n",
        "\n",
        "    # Create a blank mask and draw the ellipse\n",
        "    mask = np.zeros_like(image, dtype=np.uint8)\n",
        "    cv2.ellipse(mask, center, axes, 0, 0, 360, 1, -1)  # Angle 0, startAngle 0, endAngle 360, filled\n",
        "\n",
        "    # Optionally, remove the upper unwanted part\n",
        "    cv2.rectangle(mask, (0, 0), (width, center[1] - axes[1]), 0, -1)  # Adjust rectangle to remove top part\n",
        "    return mask"
      ],
      "metadata": {
        "id": "aTQwqVrtACJc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask_to_images(image_folder, save_folder, batch_size=50):\n",
        "    \"\"\" Apply a mask to images in batches and save the results. \"\"\"\n",
        "    for images, filenames in load_images_from_folder(image_folder, batch_size):\n",
        "        masked_images = []\n",
        "        for image in images:\n",
        "            mask = create_elliptical_mask(image)  # Create a mask for each image\n",
        "            masked_image = cv2.bitwise_and(image, image, mask=mask)  # Apply the mask to the image\n",
        "            masked_images.append(masked_image)\n",
        "        save_images(masked_images, filenames, save_folder)"
      ],
      "metadata": {
        "id": "jYrjukhWD85L"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OmalRiBZFBJF"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmentation folders and corresponding save folders\n",
        "segmentation_folders = {\n",
        "    \"/content/drive/My Drive/AIA/adaptive_mean_thresholding\": \"/content/drive/My Drive/AIA/mask/adaptive_mean_thresholding\",\n",
        "    \"/content/drive/My Drive/AIA/adaptive_gaussian_thresholding\": \"/content/drive/My Drive/AIA/mask/adaptive_gaussian_thresholding\",\n",
        "    \"/content/drive/My Drive/AIA/adaptive_niblack_thresholding\": \"/content/drive/My Drive/AIA/mask/adaptive_niblack_thresholding\",\n",
        "    \"/content/drive/My Drive/AIA/otsu_thresholding\": \"/content/drive/My Drive/AIA/mask/otsu_thresholding\"\n",
        "}"
      ],
      "metadata": {
        "id": "YQ9R1fuHFLHq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "gmuiWtY5dLWX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Apply mask to each segmentation result folder\n",
        "for input_folder, output_folder in segmentation_folders.items():\n",
        "    apply_mask_to_images(input_folder, output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "najDlsywhM1h"
      },
      "source": [
        "#Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    \"\"\" Load binary images from the folder and normalize filenames to lowercase. \"\"\"\n",
        "    images = []\n",
        "    filenames = []\n",
        "    sorted_filenames = sorted(os.listdir(folder))  # Sort filenames\n",
        "\n",
        "    for filename in sorted_filenames:\n",
        "        normalized_filename = filename.lower()  # Normalize filename to lowercase\n",
        "        img_path = os.path.join(folder, filename)  # Use original filename to form path\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img_binary = (img > 0).astype(np.uint8)  # Ensure binary format is standardized to 0 and 1\n",
        "            images.append(img_binary)\n",
        "            filenames.append(normalized_filename)  # Store normalized filename\n",
        "    return images, filenames"
      ],
      "metadata": {
        "id": "IjjicUhfrbhh"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(predictions, ground_truth):\n",
        "    \"\"\" Calculate performance metrics comparing predictions to ground truth. \"\"\"\n",
        "    TP = np.sum((predictions == 1) & (ground_truth == 1))\n",
        "    TN = np.sum((predictions == 0) & (ground_truth == 0))\n",
        "    FP = np.sum((predictions == 1) & (ground_truth == 0))\n",
        "    FN = np.sum((predictions == 0) & (ground_truth == 1))\n",
        "\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    intersection = np.sum((predictions == 1) & (ground_truth == 1))\n",
        "    union = np.sum((predictions == 1) | (ground_truth == 1))\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    dice = 2 * intersection / (np.sum(predictions) + np.sum(ground_truth)) if (np.sum(predictions) + np.sum(ground_truth)) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'specificity': specificity,\n",
        "        'f1_score': f1_score,\n",
        "        'iou': iou,\n",
        "        'dice': dice\n",
        "    }"
      ],
      "metadata": {
        "id": "h4GQ_6MXremY"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_multiple_methods(method_folders, ground_truth_folder):\n",
        "    \"\"\" Evaluate multiple segmentation methods against the same ground truth data. Normalize filenames to prevent mismatch. \"\"\"\n",
        "    ground_truth_images, gt_filenames = load_images_from_folder(ground_truth_folder)\n",
        "\n",
        "    for method, folder in method_folders.items():\n",
        "        print(f\"Evaluating method: {method}\")\n",
        "        predictions, pred_filenames = load_images_from_folder(folder)\n",
        "\n",
        "        if sorted(pred_filenames) != sorted(gt_filenames):\n",
        "            print(f\"Filename mismatch detected in {method}. Skipping this method.\")\n",
        "            continue  # Skip this method if filenames do not match\n",
        "\n",
        "        metrics_list = []\n",
        "        for pred, gt in zip(predictions, ground_truth_images):\n",
        "            metrics = calculate_metrics(pred, gt)\n",
        "            metrics_list.append(metrics)\n",
        "\n",
        "        # Print average metrics\n",
        "        avg_metrics = {k: np.mean([m[k] for m in metrics_list]) for k in metrics_list[0].keys()}\n",
        "        print_metrics(method, avg_metrics)\n"
      ],
      "metadata": {
        "id": "8dPYwFWBrh2s"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(method, metrics):\n",
        "    \"\"\" Print the calculated performance metrics for a given method. \"\"\"\n",
        "    print(f\"Method: {method}\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}, Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, Specificity: {metrics['specificity']:.4f}, F1 Score: {metrics['f1_score']:.4f}\")\n",
        "    print(f\"IoU: {metrics['iou']:.4f}, Dice Coefficient: {metrics['dice']:.4f}\")\n"
      ],
      "metadata": {
        "id": "vg9yRBwSrkt6"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define method folders and the ground truth folder\n",
        "method_folders = {\n",
        "    \"Adaptive Gaussian\": \"/content/drive/My Drive/AIA/mask/adaptive_gaussian_thresholding\",\n",
        "    \"Adaptive Mean\": \"/content/drive/My Drive/AIA/mask/adaptive_mean_thresholding\",\n",
        "    \"Adaptive Niblack\": \"/content/drive/My Drive/AIA/mask/adaptive_niblack_thresholding\",\n",
        "    \"Otsu\": \"/content/drive/My Drive/AIA/mask/otsu_thresholding\"\n",
        "}\n",
        "ground_truth_folder = '/content/drive/My Drive/AIA/teeth_mask'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RFqPmwSqrYhB"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the methods\n",
        "evaluate_multiple_methods(method_folders, ground_truth_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8dSlhkvruFl",
        "outputId": "f4721813-c5d2-4caa-ac84-80487d2417db"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating method: Adaptive Gaussian\n",
            "Method: Adaptive Gaussian\n",
            "Accuracy: 0.8714, Precision: 0.5035, Recall: 0.5968, Specificity: 0.9119, F1 Score: 0.5318\n",
            "IoU: 0.3724, Dice Coefficient: 0.5318\n",
            "Evaluating method: Adaptive Mean\n",
            "Method: Adaptive Mean\n",
            "Accuracy: 0.8599, Precision: 0.4730, Recall: 0.6183, Specificity: 0.8957, F1 Score: 0.5215\n",
            "IoU: 0.3628, Dice Coefficient: 0.5215\n",
            "Evaluating method: Adaptive Niblack\n",
            "Method: Adaptive Niblack\n",
            "Accuracy: 0.8627, Precision: 0.4782, Recall: 0.5349, Specificity: 0.9118, F1 Score: 0.4904\n",
            "IoU: 0.3329, Dice Coefficient: 0.4904\n",
            "Evaluating method: Otsu\n",
            "Method: Otsu\n",
            "Accuracy: 0.8572, Precision: 0.4708, Recall: 0.7012, Specificity: 0.8792, F1 Score: 0.5484\n",
            "IoU: 0.3910, Dice Coefficient: 0.5484\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11zgzZvFYxcEUHGFlXTW55R52rGnWgZnr",
      "authorship_tag": "ABX9TyMqkSfcPdDP2pxvKctVB9Hs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}