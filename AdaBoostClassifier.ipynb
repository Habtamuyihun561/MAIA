{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RAAyv-FD8tf75Ve35JK8O7B4hL0Tf4-T",
      "authorship_tag": "ABX9TyOPZPnXnwHgyfjeNCPw7hOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habtamuyihun561/MAIA/blob/main/AdaBoostClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "wc_n3kSv6aUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab66d3b-6cb8-47a1-eb60-6a7d21dc6aba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from scipy.stats import shapiro, probplot, anderson\n",
        "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "##\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# advanced classifiers\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "#\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "metadata": {
        "id": "_q7FhXUV6aBp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f5Ce0y1D6W1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9b8781-afd3-46e7-8cd8-668138c67f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost metrics for mean imputation: {'accuracy': 0.495875, 'precision': 0.38537063932311644, 'recall': 0.3748637250518036, 'f1': 0.34501240625460544, 'roc_auc': 0.5488072003027591, 'log_loss': 1.0932655664619588, 'error_cost': 0.863375}\n",
            "Best parameters for mean imputation: {'learning_rate': 1, 'n_estimators': 50}\n",
            "AdaBoost metrics for median imputation: {'accuracy': 0.4925, 'precision': 0.41093513565417367, 'recall': 0.37254574217525455, 'f1': 0.3429480905274021, 'roc_auc': 0.5496809596515759, 'log_loss': 1.0931294823876476, 'error_cost': 0.871375}\n",
            "Best parameters for median imputation: {'learning_rate': 1, 'n_estimators': 50}\n",
            "AdaBoost metrics for mode imputation: {'accuracy': 0.48825, 'precision': 0.32224856435382754, 'recall': 0.3611330557338556, 'f1': 0.3177142003484796, 'roc_auc': 0.5535203708884895, 'log_loss': 1.0867161511694183, 'error_cost': 0.8815}\n",
            "Best parameters for mode imputation: {'learning_rate': 0.1, 'n_estimators': 200}\n",
            "AdaBoost metrics for knn imputation: {'accuracy': 0.48875, 'precision': 0.3235576934871807, 'recall': 0.36079565715915884, 'f1': 0.31558967349466666, 'roc_auc': 0.5482932041365401, 'log_loss': 1.0868254897988403, 'error_cost': 0.8805}\n",
            "Best parameters for knn imputation: {'learning_rate': 0.1, 'n_estimators': 200}\n",
            "AdaBoost metrics for mice imputation: {'accuracy': 0.488125, 'precision': 0.32223991507431, 'recall': 0.361140599197924, 'f1': 0.31797846527145884, 'roc_auc': 0.5503982941842349, 'log_loss': 1.0867834175379325, 'error_cost': 0.88175}\n",
            "Best parameters for mice imputation: {'learning_rate': 0.1, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
        "\n",
        "# Define the error cost matrix\n",
        "error_cost_matrix = np.array([\n",
        "    [0, 1, 2],\n",
        "    [1, 0, 1],\n",
        "    [2, 1, 0]\n",
        "])\n",
        "\n",
        "# Function to calculate the custom error cost\n",
        "#def calculate_error_cost(y_true, y_pred):\n",
        "    #total_cost = 0\n",
        "    #for i in range(len(y_true)):\n",
        "       # total_cost += error_cost_matrix[y_true[i], y_pred[i]]\n",
        "    #return total_cost / len(y_true)\n",
        "\n",
        "# Function to calculate the custom error cost\n",
        "def calculate_error_cost(y_true, y_pred, cost_matrix):\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    err = np.sum(conf_matrix * cost_matrix) / len(y_true)\n",
        "    return err\n",
        "\n",
        "# Function to train and evaluate AdaBoost Classifier with Grid Search\n",
        "def evaluate_adaboost(X_train, y_train):\n",
        "    model = AdaBoostClassifier(random_state=0)\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 1, 10]\n",
        "    }\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = cross_val_predict(best_model, X_train, y_train, cv=skf)\n",
        "    y_pred_proba = cross_val_predict(best_model, X_train, y_train, cv=skf, method='predict_proba')\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_train, y_pred),\n",
        "        'precision': precision_score(y_train, y_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_train, y_pred, average='macro'),\n",
        "        'f1': f1_score(y_train, y_pred, average='macro'),\n",
        "        'roc_auc': roc_auc_score(y_train, y_pred_proba, multi_class='ovr'),\n",
        "        'log_loss': log_loss(y_train, y_pred_proba),\n",
        "        'error_cost': calculate_error_cost(y_train.to_numpy(), y_pred,error_cost_matrix)\n",
        "    }\n",
        "\n",
        "    return metrics, grid_search.best_params_\n",
        "\n",
        "# Directory containing the Lasso-selected datasets\n",
        "input_dir = '/content/drive/My Drive/Statistical Learning/selected_datasets_lasso_without_perform'\n",
        "imputation_methods = ['mean', 'median', 'mode', 'knn', 'mice']\n",
        "\n",
        "# Process each dataset\n",
        "for method in imputation_methods:\n",
        "    train_file = f'{input_dir}/{method}/train_selected_lasso_without_perform_{method}.csv'\n",
        "\n",
        "    train_df = pd.read_csv(train_file)\n",
        "\n",
        "    # Separate features and target variable\n",
        "    X_train = train_df.drop(columns=['Class'])\n",
        "    y_train = train_df['Class']\n",
        "\n",
        "    # Evaluate AdaBoost Classifier with Grid Search\n",
        "    metrics, best_params = evaluate_adaboost(X_train, y_train)\n",
        "\n",
        "    print(f\"AdaBoost metrics for {method} imputation: {metrics}\")\n",
        "    print(f\"Best parameters for {method} imputation: {best_params}\")\n"
      ]
    }
  ]
}